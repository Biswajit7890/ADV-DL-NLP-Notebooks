{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Predict Next Word with Keras .ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nw7DSxbTOqXZ"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as  np\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import seaborn as sns"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziQ5pLvUOqyq"
      },
      "source": [
        "import numpy as np\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import LSTM\n",
        "from keras.layers.core import Dense, Activation\n",
        "from keras.optimizers import RMSprop\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import heapq"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6Mge_eJOq13",
        "outputId": "002c2db5-418d-46b0-c2da-5132875138d8"
      },
      "source": [
        "path = '/content/the_tree.txt'\n",
        "text = open(path).read().lower()\n",
        "print('corpus length:', len(text))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "corpus length: 64808\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeY9ZE9ROq5P"
      },
      "source": [
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "words = tokenizer.tokenize(text)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5e-cRtzOrDG"
      },
      "source": [
        "unique_words = np.unique(words)\n",
        "unique_word_index = dict((c, i) for i, c in enumerate(unique_words))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3AnJUBJnOrJY",
        "outputId": "ae9fabe0-5b2c-4c6b-ddf8-6f6c6434aadc"
      },
      "source": [
        "WORD_LENGTH = 5\n",
        "prev_words = []\n",
        "next_words = []\n",
        "for i in range(len(words) - WORD_LENGTH):\n",
        "    prev_words.append(words[i:i + WORD_LENGTH])\n",
        "    next_words.append(words[i + WORD_LENGTH])\n",
        "print(prev_words[36])\n",
        "print(next_words[6])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['you', 'he', 'said', 'aiken', 'frowned']\n",
            "but\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEnkI2qBOrMf",
        "outputId": "67661e6a-7b7b-4b69-ca96-cfe9bd2cf106"
      },
      "source": [
        "prev_words[:5]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['the', 'tree', 'by', 'k', 'm'],\n",
              " ['tree', 'by', 'k', 'm', 'fox'],\n",
              " ['by', 'k', 'm', 'fox', 'the'],\n",
              " ['k', 'm', 'fox', 'the', 'tree'],\n",
              " ['m', 'fox', 'the', 'tree', 'chapter']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrdQtpFmOrSw"
      },
      "source": [
        "X = np.zeros((len(prev_words), WORD_LENGTH, len(unique_words)), dtype=bool)\n",
        "Y = np.zeros((len(next_words), len(unique_words)), dtype=bool)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TShCWmwPne2N"
      },
      "source": [
        "for i, each_words in enumerate(prev_words):\n",
        "    for j, each_word in enumerate(each_words):\n",
        "        X[i, j, unique_word_index[each_word]] = 1\n",
        "    Y[i, unique_word_index[next_words[i]]] = 1"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bllxze5lne9-",
        "outputId": "51791d76-cf1c-49bc-d73f-277755321521"
      },
      "source": [
        "print(X[:20])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[False False False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]]\n",
            "\n",
            " [[False False False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]]\n",
            "\n",
            " [[False False False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[False False False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]]\n",
            "\n",
            " [[False False False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]]\n",
            "\n",
            " [[False False False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUvO_X1JnfBV",
        "outputId": "9f7676c1-bd3a-4592-a035-d15999943e85"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(WORD_LENGTH, len(unique_words))))\n",
        "model.add(Dense(len(unique_words)))\n",
        "model.add(Activation('softmax'))\n",
        "optimizer = RMSprop(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "history = model.fit(X, Y, validation_split=0.05, batch_size=128, epochs=125, shuffle=True).history"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/125\n",
            "90/90 [==============================] - 13s 122ms/step - loss: 6.7681 - accuracy: 0.0465 - val_loss: 6.1332 - val_accuracy: 0.0745\n",
            "Epoch 2/125\n",
            "90/90 [==============================] - 11s 117ms/step - loss: 5.8915 - accuracy: 0.0877 - val_loss: 5.8890 - val_accuracy: 0.1275\n",
            "Epoch 3/125\n",
            "90/90 [==============================] - 10s 116ms/step - loss: 5.2446 - accuracy: 0.1359 - val_loss: 5.8214 - val_accuracy: 0.1192\n",
            "Epoch 4/125\n",
            "90/90 [==============================] - 11s 117ms/step - loss: 4.5460 - accuracy: 0.1991 - val_loss: 6.0676 - val_accuracy: 0.0877\n",
            "Epoch 5/125\n",
            "90/90 [==============================] - 10s 117ms/step - loss: 3.7887 - accuracy: 0.2924 - val_loss: 6.3224 - val_accuracy: 0.0728\n",
            "Epoch 6/125\n",
            "90/90 [==============================] - 10s 115ms/step - loss: 3.0559 - accuracy: 0.4218 - val_loss: 6.7380 - val_accuracy: 0.0596\n",
            "Epoch 7/125\n",
            "90/90 [==============================] - 10s 115ms/step - loss: 2.4703 - accuracy: 0.5324 - val_loss: 7.0757 - val_accuracy: 0.0728\n",
            "Epoch 8/125\n",
            "90/90 [==============================] - 10s 116ms/step - loss: 1.9511 - accuracy: 0.6432 - val_loss: 7.3753 - val_accuracy: 0.0613\n",
            "Epoch 9/125\n",
            "90/90 [==============================] - 10s 117ms/step - loss: 1.5047 - accuracy: 0.7457 - val_loss: 7.5924 - val_accuracy: 0.0530\n",
            "Epoch 10/125\n",
            "90/90 [==============================] - 11s 117ms/step - loss: 1.2137 - accuracy: 0.7960 - val_loss: 7.9125 - val_accuracy: 0.0530\n",
            "Epoch 11/125\n",
            "90/90 [==============================] - 11s 117ms/step - loss: 0.9674 - accuracy: 0.8468 - val_loss: 8.0281 - val_accuracy: 0.0414\n",
            "Epoch 12/125\n",
            "90/90 [==============================] - 11s 117ms/step - loss: 0.7625 - accuracy: 0.8922 - val_loss: 8.0229 - val_accuracy: 0.0546\n",
            "Epoch 13/125\n",
            "90/90 [==============================] - 11s 118ms/step - loss: 0.6338 - accuracy: 0.9116 - val_loss: 8.1646 - val_accuracy: 0.0530\n",
            "Epoch 14/125\n",
            "90/90 [==============================] - 11s 118ms/step - loss: 0.5106 - accuracy: 0.9386 - val_loss: 8.1371 - val_accuracy: 0.0530\n",
            "Epoch 15/125\n",
            "90/90 [==============================] - 11s 118ms/step - loss: 0.4416 - accuracy: 0.9478 - val_loss: 8.0980 - val_accuracy: 0.0497\n",
            "Epoch 16/125\n",
            "90/90 [==============================] - 11s 118ms/step - loss: 0.3978 - accuracy: 0.9584 - val_loss: 8.1914 - val_accuracy: 0.0430\n",
            "Epoch 17/125\n",
            "90/90 [==============================] - 11s 118ms/step - loss: 0.3588 - accuracy: 0.9625 - val_loss: 8.1488 - val_accuracy: 0.0430\n",
            "Epoch 18/125\n",
            "90/90 [==============================] - 10s 116ms/step - loss: 0.3567 - accuracy: 0.9647 - val_loss: 8.0637 - val_accuracy: 0.0480\n",
            "Epoch 19/125\n",
            "90/90 [==============================] - 10s 116ms/step - loss: 0.3308 - accuracy: 0.9693 - val_loss: 8.1251 - val_accuracy: 0.0464\n",
            "Epoch 20/125\n",
            "90/90 [==============================] - 10s 115ms/step - loss: 0.3266 - accuracy: 0.9705 - val_loss: 8.1013 - val_accuracy: 0.0414\n",
            "Epoch 21/125\n",
            "90/90 [==============================] - 11s 123ms/step - loss: 0.3312 - accuracy: 0.9699 - val_loss: 8.0847 - val_accuracy: 0.0546\n",
            "Epoch 22/125\n",
            "90/90 [==============================] - 10s 116ms/step - loss: 0.3207 - accuracy: 0.9721 - val_loss: 8.0100 - val_accuracy: 0.0464\n",
            "Epoch 23/125\n",
            "90/90 [==============================] - 11s 118ms/step - loss: 0.3244 - accuracy: 0.9702 - val_loss: 7.9710 - val_accuracy: 0.0430\n",
            "Epoch 24/125\n",
            "90/90 [==============================] - 11s 117ms/step - loss: 0.3417 - accuracy: 0.9673 - val_loss: 8.0136 - val_accuracy: 0.0331\n",
            "Epoch 25/125\n",
            "90/90 [==============================] - 11s 118ms/step - loss: 0.3513 - accuracy: 0.9654 - val_loss: 7.9207 - val_accuracy: 0.0513\n",
            "Epoch 26/125\n",
            "90/90 [==============================] - 11s 120ms/step - loss: 0.3849 - accuracy: 0.9615 - val_loss: 7.9141 - val_accuracy: 0.0497\n",
            "Epoch 27/125\n",
            "90/90 [==============================] - 11s 119ms/step - loss: 0.3749 - accuracy: 0.9654 - val_loss: 7.8310 - val_accuracy: 0.0430\n",
            "Epoch 28/125\n",
            "90/90 [==============================] - 11s 119ms/step - loss: 0.3854 - accuracy: 0.9610 - val_loss: 8.0260 - val_accuracy: 0.0364\n",
            "Epoch 29/125\n",
            "90/90 [==============================] - 11s 118ms/step - loss: 0.3914 - accuracy: 0.9614 - val_loss: 8.0323 - val_accuracy: 0.0331\n",
            "Epoch 30/125\n",
            "90/90 [==============================] - 11s 118ms/step - loss: 0.3987 - accuracy: 0.9646 - val_loss: 7.9478 - val_accuracy: 0.0397\n",
            "Epoch 31/125\n",
            "90/90 [==============================] - 11s 117ms/step - loss: 0.4328 - accuracy: 0.9588 - val_loss: 7.9728 - val_accuracy: 0.0447\n",
            "Epoch 32/125\n",
            "90/90 [==============================] - 11s 117ms/step - loss: 0.4252 - accuracy: 0.9579 - val_loss: 7.9697 - val_accuracy: 0.0447\n",
            "Epoch 33/125\n",
            "90/90 [==============================] - 11s 118ms/step - loss: 0.4664 - accuracy: 0.9536 - val_loss: 7.9542 - val_accuracy: 0.0348\n",
            "Epoch 34/125\n",
            "90/90 [==============================] - 11s 118ms/step - loss: 0.4482 - accuracy: 0.9582 - val_loss: 8.0136 - val_accuracy: 0.0381\n",
            "Epoch 35/125\n",
            "90/90 [==============================] - 10s 116ms/step - loss: 0.4507 - accuracy: 0.9571 - val_loss: 8.0577 - val_accuracy: 0.0348\n",
            "Epoch 36/125\n",
            "90/90 [==============================] - 11s 118ms/step - loss: 0.4376 - accuracy: 0.9617 - val_loss: 8.0131 - val_accuracy: 0.0430\n",
            "Epoch 37/125\n",
            "90/90 [==============================] - 10s 117ms/step - loss: 0.4640 - accuracy: 0.9549 - val_loss: 8.1220 - val_accuracy: 0.0381\n",
            "Epoch 38/125\n",
            "90/90 [==============================] - 11s 119ms/step - loss: 0.4569 - accuracy: 0.9606 - val_loss: 8.1370 - val_accuracy: 0.0397\n",
            "Epoch 39/125\n",
            "90/90 [==============================] - 11s 119ms/step - loss: 0.4709 - accuracy: 0.9585 - val_loss: 8.1256 - val_accuracy: 0.0364\n",
            "Epoch 40/125\n",
            "90/90 [==============================] - 11s 120ms/step - loss: 0.4870 - accuracy: 0.9575 - val_loss: 8.2011 - val_accuracy: 0.0447\n",
            "Epoch 41/125\n",
            "90/90 [==============================] - 11s 119ms/step - loss: 0.4636 - accuracy: 0.9603 - val_loss: 8.2416 - val_accuracy: 0.0364\n",
            "Epoch 42/125\n",
            "90/90 [==============================] - 11s 119ms/step - loss: 0.4953 - accuracy: 0.9538 - val_loss: 8.2965 - val_accuracy: 0.0397\n",
            "Epoch 43/125\n",
            "90/90 [==============================] - 11s 119ms/step - loss: 0.4726 - accuracy: 0.9601 - val_loss: 8.2694 - val_accuracy: 0.0281\n",
            "Epoch 44/125\n",
            "90/90 [==============================] - 11s 120ms/step - loss: 0.5002 - accuracy: 0.9572 - val_loss: 8.3261 - val_accuracy: 0.0397\n",
            "Epoch 45/125\n",
            "90/90 [==============================] - 11s 120ms/step - loss: 0.4947 - accuracy: 0.9597 - val_loss: 8.3393 - val_accuracy: 0.0298\n",
            "Epoch 46/125\n",
            "90/90 [==============================] - 11s 120ms/step - loss: 0.4887 - accuracy: 0.9584 - val_loss: 8.3599 - val_accuracy: 0.0298\n",
            "Epoch 47/125\n",
            "90/90 [==============================] - 11s 120ms/step - loss: 0.4892 - accuracy: 0.9600 - val_loss: 8.4568 - val_accuracy: 0.0298\n",
            "Epoch 48/125\n",
            "90/90 [==============================] - 11s 119ms/step - loss: 0.4905 - accuracy: 0.9588 - val_loss: 8.3621 - val_accuracy: 0.0364\n",
            "Epoch 49/125\n",
            "90/90 [==============================] - 11s 119ms/step - loss: 0.4681 - accuracy: 0.9618 - val_loss: 8.5155 - val_accuracy: 0.0397\n",
            "Epoch 50/125\n",
            "90/90 [==============================] - 11s 124ms/step - loss: 0.4980 - accuracy: 0.9567 - val_loss: 8.5016 - val_accuracy: 0.0281\n",
            "Epoch 51/125\n",
            "90/90 [==============================] - 11s 121ms/step - loss: 0.4713 - accuracy: 0.9616 - val_loss: 8.5330 - val_accuracy: 0.0430\n",
            "Epoch 52/125\n",
            "90/90 [==============================] - 11s 119ms/step - loss: 0.4845 - accuracy: 0.9622 - val_loss: 8.5862 - val_accuracy: 0.0348\n",
            "Epoch 53/125\n",
            "90/90 [==============================] - 11s 120ms/step - loss: 0.4579 - accuracy: 0.9654 - val_loss: 8.5647 - val_accuracy: 0.0364\n",
            "Epoch 54/125\n",
            "90/90 [==============================] - 11s 122ms/step - loss: 0.4866 - accuracy: 0.9623 - val_loss: 8.6281 - val_accuracy: 0.0348\n",
            "Epoch 55/125\n",
            "90/90 [==============================] - 11s 120ms/step - loss: 0.4843 - accuracy: 0.9642 - val_loss: 8.6243 - val_accuracy: 0.0348\n",
            "Epoch 56/125\n",
            "90/90 [==============================] - 11s 120ms/step - loss: 0.4998 - accuracy: 0.9581 - val_loss: 8.6499 - val_accuracy: 0.0281\n",
            "Epoch 57/125\n",
            "90/90 [==============================] - 11s 119ms/step - loss: 0.4794 - accuracy: 0.9634 - val_loss: 8.6504 - val_accuracy: 0.0298\n",
            "Epoch 58/125\n",
            "90/90 [==============================] - 11s 120ms/step - loss: 0.4834 - accuracy: 0.9624 - val_loss: 8.6845 - val_accuracy: 0.0364\n",
            "Epoch 59/125\n",
            "90/90 [==============================] - 11s 121ms/step - loss: 0.4935 - accuracy: 0.9655 - val_loss: 8.7448 - val_accuracy: 0.0298\n",
            "Epoch 60/125\n",
            "90/90 [==============================] - 11s 121ms/step - loss: 0.4759 - accuracy: 0.9648 - val_loss: 8.7213 - val_accuracy: 0.0348\n",
            "Epoch 61/125\n",
            "90/90 [==============================] - 11s 121ms/step - loss: 0.4729 - accuracy: 0.9664 - val_loss: 8.7423 - val_accuracy: 0.0281\n",
            "Epoch 62/125\n",
            "90/90 [==============================] - 11s 120ms/step - loss: 0.4754 - accuracy: 0.9648 - val_loss: 8.7476 - val_accuracy: 0.0315\n",
            "Epoch 63/125\n",
            "90/90 [==============================] - 11s 120ms/step - loss: 0.5029 - accuracy: 0.9650 - val_loss: 8.8049 - val_accuracy: 0.0348\n",
            "Epoch 64/125\n",
            "90/90 [==============================] - 11s 118ms/step - loss: 0.4748 - accuracy: 0.9664 - val_loss: 8.7319 - val_accuracy: 0.0414\n",
            "Epoch 65/125\n",
            "90/90 [==============================] - 11s 119ms/step - loss: 0.4877 - accuracy: 0.9653 - val_loss: 8.7229 - val_accuracy: 0.0364\n",
            "Epoch 66/125\n",
            "90/90 [==============================] - 11s 120ms/step - loss: 0.4737 - accuracy: 0.9660 - val_loss: 8.8391 - val_accuracy: 0.0298\n",
            "Epoch 67/125\n",
            "90/90 [==============================] - 11s 120ms/step - loss: 0.4674 - accuracy: 0.9661 - val_loss: 8.7669 - val_accuracy: 0.0331\n",
            "Epoch 68/125\n",
            "90/90 [==============================] - 11s 119ms/step - loss: 0.4787 - accuracy: 0.9666 - val_loss: 8.7840 - val_accuracy: 0.0381\n",
            "Epoch 69/125\n",
            "90/90 [==============================] - 11s 121ms/step - loss: 0.4756 - accuracy: 0.9686 - val_loss: 8.9495 - val_accuracy: 0.0331\n",
            "Epoch 70/125\n",
            "90/90 [==============================] - 11s 120ms/step - loss: 0.4713 - accuracy: 0.9659 - val_loss: 8.7722 - val_accuracy: 0.0298\n",
            "Epoch 71/125\n",
            "90/90 [==============================] - 11s 120ms/step - loss: 0.5015 - accuracy: 0.9662 - val_loss: 8.8703 - val_accuracy: 0.0331\n",
            "Epoch 72/125\n",
            "90/90 [==============================] - 11s 120ms/step - loss: 0.4734 - accuracy: 0.9677 - val_loss: 8.9260 - val_accuracy: 0.0298\n",
            "Epoch 73/125\n",
            "90/90 [==============================] - 11s 120ms/step - loss: 0.4821 - accuracy: 0.9674 - val_loss: 8.9308 - val_accuracy: 0.0315\n",
            "Epoch 74/125\n",
            "90/90 [==============================] - 11s 119ms/step - loss: 0.4893 - accuracy: 0.9660 - val_loss: 8.8415 - val_accuracy: 0.0315\n",
            "Epoch 75/125\n",
            "90/90 [==============================] - 11s 119ms/step - loss: 0.4581 - accuracy: 0.9673 - val_loss: 8.8972 - val_accuracy: 0.0381\n",
            "Epoch 76/125\n",
            "90/90 [==============================] - 11s 119ms/step - loss: 0.4551 - accuracy: 0.9704 - val_loss: 8.9383 - val_accuracy: 0.0397\n",
            "Epoch 77/125\n",
            "90/90 [==============================] - 11s 120ms/step - loss: 0.4626 - accuracy: 0.9687 - val_loss: 8.8527 - val_accuracy: 0.0364\n",
            "Epoch 78/125\n",
            "90/90 [==============================] - 11s 121ms/step - loss: 0.4823 - accuracy: 0.9658 - val_loss: 8.9167 - val_accuracy: 0.0348\n",
            "Epoch 79/125\n",
            "90/90 [==============================] - 11s 127ms/step - loss: 0.4644 - accuracy: 0.9674 - val_loss: 8.9326 - val_accuracy: 0.0331\n",
            "Epoch 80/125\n",
            "90/90 [==============================] - 11s 120ms/step - loss: 0.4904 - accuracy: 0.9677 - val_loss: 8.9202 - val_accuracy: 0.0315\n",
            "Epoch 81/125\n",
            "90/90 [==============================] - 11s 119ms/step - loss: 0.4839 - accuracy: 0.9664 - val_loss: 8.9177 - val_accuracy: 0.0348\n",
            "Epoch 82/125\n",
            "90/90 [==============================] - 11s 122ms/step - loss: 0.4609 - accuracy: 0.9681 - val_loss: 8.9586 - val_accuracy: 0.0331\n",
            "Epoch 83/125\n",
            "90/90 [==============================] - 11s 122ms/step - loss: 0.4838 - accuracy: 0.9678 - val_loss: 8.8876 - val_accuracy: 0.0364\n",
            "Epoch 84/125\n",
            "90/90 [==============================] - 11s 121ms/step - loss: 0.4808 - accuracy: 0.9674 - val_loss: 8.9938 - val_accuracy: 0.0364\n",
            "Epoch 85/125\n",
            "90/90 [==============================] - 11s 120ms/step - loss: 0.4833 - accuracy: 0.9671 - val_loss: 8.9167 - val_accuracy: 0.0414\n",
            "Epoch 86/125\n",
            "90/90 [==============================] - 11s 119ms/step - loss: 0.4798 - accuracy: 0.9658 - val_loss: 8.9450 - val_accuracy: 0.0281\n",
            "Epoch 87/125\n",
            "90/90 [==============================] - 11s 120ms/step - loss: 0.4740 - accuracy: 0.9672 - val_loss: 8.9601 - val_accuracy: 0.0315\n",
            "Epoch 88/125\n",
            "90/90 [==============================] - 11s 119ms/step - loss: 0.4718 - accuracy: 0.9685 - val_loss: 9.0100 - val_accuracy: 0.0315\n",
            "Epoch 89/125\n",
            "90/90 [==============================] - 11s 119ms/step - loss: 0.4738 - accuracy: 0.9699 - val_loss: 8.9632 - val_accuracy: 0.0331\n",
            "Epoch 90/125\n",
            "90/90 [==============================] - 11s 119ms/step - loss: 0.4557 - accuracy: 0.9699 - val_loss: 8.9752 - val_accuracy: 0.0331\n",
            "Epoch 91/125\n",
            "90/90 [==============================] - 11s 119ms/step - loss: 0.4483 - accuracy: 0.9686 - val_loss: 9.0443 - val_accuracy: 0.0397\n",
            "Epoch 92/125\n",
            "90/90 [==============================] - 11s 119ms/step - loss: 0.4885 - accuracy: 0.9686 - val_loss: 8.9784 - val_accuracy: 0.0298\n",
            "Epoch 93/125\n",
            "90/90 [==============================] - 11s 119ms/step - loss: 0.4562 - accuracy: 0.9686 - val_loss: 8.9656 - val_accuracy: 0.0248\n",
            "Epoch 94/125\n",
            "90/90 [==============================] - 11s 119ms/step - loss: 0.4772 - accuracy: 0.9695 - val_loss: 9.0526 - val_accuracy: 0.0298\n",
            "Epoch 95/125\n",
            "90/90 [==============================] - 11s 119ms/step - loss: 0.4727 - accuracy: 0.9678 - val_loss: 8.9427 - val_accuracy: 0.0281\n",
            "Epoch 96/125\n",
            "90/90 [==============================] - 11s 119ms/step - loss: 0.4744 - accuracy: 0.9671 - val_loss: 9.0343 - val_accuracy: 0.0281\n",
            "Epoch 97/125\n",
            "90/90 [==============================] - 11s 120ms/step - loss: 0.4576 - accuracy: 0.9684 - val_loss: 9.0893 - val_accuracy: 0.0298\n",
            "Epoch 98/125\n",
            "90/90 [==============================] - 11s 119ms/step - loss: 0.4821 - accuracy: 0.9668 - val_loss: 9.0934 - val_accuracy: 0.0331\n",
            "Epoch 99/125\n",
            "90/90 [==============================] - 11s 119ms/step - loss: 0.4693 - accuracy: 0.9676 - val_loss: 9.1666 - val_accuracy: 0.0281\n",
            "Epoch 100/125\n",
            "90/90 [==============================] - 11s 119ms/step - loss: 0.4556 - accuracy: 0.9712 - val_loss: 9.1335 - val_accuracy: 0.0315\n",
            "Epoch 101/125\n",
            "90/90 [==============================] - 11s 120ms/step - loss: 0.4657 - accuracy: 0.9679 - val_loss: 9.1135 - val_accuracy: 0.0265\n",
            "Epoch 102/125\n",
            "90/90 [==============================] - 11s 120ms/step - loss: 0.4746 - accuracy: 0.9687 - val_loss: 9.0821 - val_accuracy: 0.0298\n",
            "Epoch 103/125\n",
            "90/90 [==============================] - 11s 120ms/step - loss: 0.5136 - accuracy: 0.9691 - val_loss: 9.0817 - val_accuracy: 0.0331\n",
            "Epoch 104/125\n",
            "90/90 [==============================] - 11s 119ms/step - loss: 0.4704 - accuracy: 0.9692 - val_loss: 9.1114 - val_accuracy: 0.0281\n",
            "Epoch 105/125\n",
            "90/90 [==============================] - 11s 119ms/step - loss: 0.4792 - accuracy: 0.9691 - val_loss: 9.0044 - val_accuracy: 0.0265\n",
            "Epoch 106/125\n",
            "90/90 [==============================] - 11s 118ms/step - loss: 0.4899 - accuracy: 0.9679 - val_loss: 9.0549 - val_accuracy: 0.0348\n",
            "Epoch 107/125\n",
            "90/90 [==============================] - 11s 120ms/step - loss: 0.4521 - accuracy: 0.9716 - val_loss: 9.1080 - val_accuracy: 0.0248\n",
            "Epoch 108/125\n",
            "90/90 [==============================] - 11s 124ms/step - loss: 0.4670 - accuracy: 0.9697 - val_loss: 9.0572 - val_accuracy: 0.0248\n",
            "Epoch 109/125\n",
            "90/90 [==============================] - 11s 120ms/step - loss: 0.4610 - accuracy: 0.9685 - val_loss: 9.1115 - val_accuracy: 0.0348\n",
            "Epoch 110/125\n",
            "90/90 [==============================] - 11s 119ms/step - loss: 0.4807 - accuracy: 0.9703 - val_loss: 9.0629 - val_accuracy: 0.0281\n",
            "Epoch 111/125\n",
            "90/90 [==============================] - 11s 120ms/step - loss: 0.4428 - accuracy: 0.9702 - val_loss: 9.0022 - val_accuracy: 0.0315\n",
            "Epoch 112/125\n",
            "90/90 [==============================] - 11s 119ms/step - loss: 0.4742 - accuracy: 0.9680 - val_loss: 9.0037 - val_accuracy: 0.0331\n",
            "Epoch 113/125\n",
            "90/90 [==============================] - 11s 120ms/step - loss: 0.4687 - accuracy: 0.9688 - val_loss: 9.0938 - val_accuracy: 0.0298\n",
            "Epoch 114/125\n",
            "90/90 [==============================] - 11s 120ms/step - loss: 0.4685 - accuracy: 0.9710 - val_loss: 9.0161 - val_accuracy: 0.0331\n",
            "Epoch 115/125\n",
            "90/90 [==============================] - 11s 120ms/step - loss: 0.4694 - accuracy: 0.9699 - val_loss: 9.0092 - val_accuracy: 0.0348\n",
            "Epoch 116/125\n",
            "90/90 [==============================] - 11s 120ms/step - loss: 0.4780 - accuracy: 0.9701 - val_loss: 9.1621 - val_accuracy: 0.0364\n",
            "Epoch 117/125\n",
            "90/90 [==============================] - 11s 120ms/step - loss: 0.4717 - accuracy: 0.9703 - val_loss: 9.1059 - val_accuracy: 0.0315\n",
            "Epoch 118/125\n",
            "90/90 [==============================] - 11s 119ms/step - loss: 0.4490 - accuracy: 0.9706 - val_loss: 9.1469 - val_accuracy: 0.0298\n",
            "Epoch 119/125\n",
            "90/90 [==============================] - 11s 121ms/step - loss: 0.4808 - accuracy: 0.9678 - val_loss: 9.0840 - val_accuracy: 0.0348\n",
            "Epoch 120/125\n",
            "90/90 [==============================] - 11s 121ms/step - loss: 0.4609 - accuracy: 0.9700 - val_loss: 9.1342 - val_accuracy: 0.0298\n",
            "Epoch 121/125\n",
            "90/90 [==============================] - 11s 120ms/step - loss: 0.4844 - accuracy: 0.9686 - val_loss: 9.1251 - val_accuracy: 0.0315\n",
            "Epoch 122/125\n",
            "90/90 [==============================] - 11s 120ms/step - loss: 0.4823 - accuracy: 0.9703 - val_loss: 9.0776 - val_accuracy: 0.0348\n",
            "Epoch 123/125\n",
            "90/90 [==============================] - 11s 119ms/step - loss: 0.4648 - accuracy: 0.9681 - val_loss: 9.0741 - val_accuracy: 0.0315\n",
            "Epoch 124/125\n",
            "90/90 [==============================] - 11s 120ms/step - loss: 0.4683 - accuracy: 0.9717 - val_loss: 9.1532 - val_accuracy: 0.0298\n",
            "Epoch 125/125\n",
            "90/90 [==============================] - 11s 120ms/step - loss: 0.4555 - accuracy: 0.9714 - val_loss: 9.1054 - val_accuracy: 0.0348\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUyPXZcVnfEy"
      },
      "source": [
        "model.save('keras_next_word_model.h5')\n",
        "pickle.dump(history, open(\"history.p\", \"wb\"))\n",
        "model = load_model('keras_next_word_model.h5')\n",
        "history = pickle.load(open(\"history.p\", \"rb\"))"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yg9bJmjzOrWf",
        "outputId": "f5b8d8c6-63ad-4818-ae0a-d363158c291d"
      },
      "source": [
        "history"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [0.05411066487431526,\n",
              "  0.09094082564115524,\n",
              "  0.1350148320198059,\n",
              "  0.1857217699289322,\n",
              "  0.2672368586063385,\n",
              "  0.371879905462265,\n",
              "  0.48141035437583923,\n",
              "  0.5826496481895447,\n",
              "  0.6796125173568726,\n",
              "  0.7545819282531738,\n",
              "  0.8064234852790833,\n",
              "  0.8470937609672546,\n",
              "  0.8724035620689392,\n",
              "  0.8924768567085266,\n",
              "  0.9068772792816162,\n",
              "  0.9183976054191589,\n",
              "  0.9223250150680542,\n",
              "  0.9297434091567993,\n",
              "  0.9352417588233948,\n",
              "  0.9350671768188477,\n",
              "  0.9338453412055969,\n",
              "  0.9328853487968445,\n",
              "  0.933147132396698,\n",
              "  0.9343690276145935,\n",
              "  0.9314016699790955],\n",
              " 'loss': [6.483112335205078,\n",
              "  5.837347507476807,\n",
              "  5.26887845993042,\n",
              "  4.682735443115234,\n",
              "  4.028784275054932,\n",
              "  3.377232789993286,\n",
              "  2.7777469158172607,\n",
              "  2.2542479038238525,\n",
              "  1.8111088275909424,\n",
              "  1.4569590091705322,\n",
              "  1.1947365999221802,\n",
              "  0.9976547360420227,\n",
              "  0.85457843542099,\n",
              "  0.7630259394645691,\n",
              "  0.6823788285255432,\n",
              "  0.63102126121521,\n",
              "  0.6010006666183472,\n",
              "  0.5663062334060669,\n",
              "  0.5420355796813965,\n",
              "  0.5387985706329346,\n",
              "  0.5490317940711975,\n",
              "  0.5510519742965698,\n",
              "  0.5652149319648743,\n",
              "  0.5561950206756592,\n",
              "  0.5683572888374329],\n",
              " 'val_accuracy': [0.06456953287124634,\n",
              "  0.1192052960395813,\n",
              "  0.11258278042078018,\n",
              "  0.09271523356437683,\n",
              "  0.09271523356437683,\n",
              "  0.08940397202968597,\n",
              "  0.08609271794557571,\n",
              "  0.07119205594062805,\n",
              "  0.07615894079208374,\n",
              "  0.07615894079208374,\n",
              "  0.08112582564353943,\n",
              "  0.05960264801979065,\n",
              "  0.05960264801979065,\n",
              "  0.06953642517328262,\n",
              "  0.05960264801979065,\n",
              "  0.06456953287124634,\n",
              "  0.06456953287124634,\n",
              "  0.06125827878713608,\n",
              "  0.05298013240098953,\n",
              "  0.05794702097773552,\n",
              "  0.05463576316833496,\n",
              "  0.05794702097773552,\n",
              "  0.051324501633644104,\n",
              "  0.05960264801979065,\n",
              "  0.05794702097773552],\n",
              " 'val_loss': [6.251062870025635,\n",
              "  5.840312957763672,\n",
              "  5.825451850891113,\n",
              "  5.9486775398254395,\n",
              "  6.362576484680176,\n",
              "  6.5306477546691895,\n",
              "  6.968185901641846,\n",
              "  7.178881645202637,\n",
              "  7.3797197341918945,\n",
              "  7.805734157562256,\n",
              "  7.8754987716674805,\n",
              "  8.071630477905273,\n",
              "  8.204660415649414,\n",
              "  8.207817077636719,\n",
              "  8.099502563476562,\n",
              "  8.04887866973877,\n",
              "  8.140605926513672,\n",
              "  8.011155128479004,\n",
              "  8.121429443359375,\n",
              "  7.9831461906433105,\n",
              "  7.976590156555176,\n",
              "  7.932995319366455,\n",
              "  7.937902450561523,\n",
              "  7.9347028732299805,\n",
              "  7.848381519317627]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDWQxpSguJag"
      },
      "source": [
        "def prepare_input(text):\n",
        "    x = np.zeros((1, WORD_LENGTH, len(unique_words)))\n",
        "    for t, word in enumerate(text.split()):\n",
        "        print(word)\n",
        "        x[0, t, unique_word_index[word]] = 1\n",
        "        return x"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Co4c6njpuJhV"
      },
      "source": [
        "def sample(preds, top_n=3):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds)\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    return heapq.nlargest(top_n, range(len(preds)), preds.take)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgKU3ynGuJkv"
      },
      "source": [
        "def predict_completions(text, n=3):\n",
        "    if text == \"\":\n",
        "        return(\"0\")\n",
        "    x = prepare_input(text)\n",
        "    preds = model.predict(x, verbose=0)[0]\n",
        "    next_indices = sample(preds, n)\n",
        "    return [unique_words[idx] for idx in next_indices]"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6O1uBIhZuJnp",
        "outputId": "ccd83825-f2d4-47c7-cbb4-5c860d82305d"
      },
      "source": [
        "q =  \"one day i will beccome\"\n",
        "print(\"correct sentence: \",q)\n",
        "seq = \" \".join(tokenizer.tokenize(q.lower()))\n",
        "print(\"Sequence: \",seq)\n",
        "print(\"next possible words: \", predict_completions(seq, 5))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "correct sentence:  one day i will beccome\n",
            "Sequence:  one day i will beccome\n",
            "one\n",
            "next possible words:  ['mother', 'again', 'him', 'woman', 'could']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyBnYvgvuJqt",
        "outputId": "6c110269-e1e9-45b0-ffbb-90087818788f"
      },
      "source": [
        "q =  \"nothing for the\"\n",
        "print(\"correct sentence: \",q)\n",
        "seq = \" \".join(tokenizer.tokenize(q.lower()))\n",
        "print(\"Sequence: \",seq)\n",
        "print(\"next possible words: \", predict_completions(seq, 5))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "correct sentence:  nothing for the\n",
            "Sequence:  nothing for the\n",
            "nothing\n",
            "next possible words:  ['thing', 'sort', 'get', 'commented', 'tried']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHNr7hGtuJtz",
        "outputId": "6e315f9e-657f-4162-8c7a-522147d1347e"
      },
      "source": [
        "q =  \"Altogether\"\n",
        "print(\"correct sentence: \",q)\n",
        "seq = \" \".join(tokenizer.tokenize(q.lower()))\n",
        "print(\"Sequence: \",seq)\n",
        "print(\"next possible words: \", predict_completions(seq, 5))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "correct sentence:  Altogether\n",
            "Sequence:  altogether\n",
            "altogether\n",
            "next possible words:  ['look', 'he', 'where', 'ash', 'okay']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2m57JDhuJwt",
        "outputId": "0bdac5c2-0ac6-4782-fae7-01f495a8f98c"
      },
      "source": [
        "q =  \"hard to believe that\"\n",
        "print(\"correct sentence: \",q)\n",
        "seq = \" \".join(tokenizer.tokenize(q.lower()))\n",
        "print(\"Sequence: \",seq)\n",
        "print(\"next possible words: \", predict_completions(seq, 5))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "correct sentence:  hard to believe that\n",
            "Sequence:  hard to believe that\n",
            "hard\n",
            "next possible words:  ['son', 'coughed', 'march', 'sharp', 'brush']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpNVauQ94CAf",
        "outputId": "3ab276a6-f9e5-4894-e4d9-6cb78f051622"
      },
      "source": [
        "q =  \"Now you must\"\n",
        "print(\"correct sentence: \",q)\n",
        "seq = \" \".join(tokenizer.tokenize(q.lower()))\n",
        "print(\"Sequence: \",seq)\n",
        "print(\"next possible words: \", predict_completions(seq, 5))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "correct sentence:  Now you must\n",
            "Sequence:  now you must\n",
            "now\n",
            "next possible words:  ['of', 'covering', 'if', 'but', 'else']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ww2ghIv94JYH",
        "outputId": "80e44917-7fe9-47ef-cf7d-0183761a0580"
      },
      "source": [
        "q =  \"Same day i tried to\"\n",
        "print(\"correct sentence: \",q)\n",
        "seq = \" \".join(tokenizer.tokenize(q.lower()))\n",
        "print(\"Sequence: \",seq)\n",
        "print(\"next possible words: \", predict_completions(seq, 5))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "correct sentence:  Same day i tried to\n",
            "Sequence:  same day i tried to\n",
            "same\n",
            "next possible words:  ['bought', 'safe', 'standing', 'understood', 'god']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}